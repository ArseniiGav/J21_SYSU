{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "vm = input()\n",
    "if vm.lower()=='yes':\n",
    "    vm=True\n",
    "else:\n",
    "    vm=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vm:\n",
    "    path='/mnt/cephfs/ml_data/mc_2021/processed_data/ProcessedTrainReal/'\n",
    "    data_real = pd.read_csv('{}ProcessedTrain_1M.csv.gz'.format(path))\n",
    "else:\n",
    "    data_real = pd.read_csv('processed_data/ProcessedTrainReal/ProcessedTrain_1M.csv.gz')\n",
    "\n",
    "data_real = data_real[data_real['edepR'] < 17.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = len(data_real.columns) - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_energy = data_real['edep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = data_real[size:]\n",
    "val_en = target_energy[size:]\n",
    "\n",
    "data_real = data_real[:size]\n",
    "target_energy = target_energy[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_folds = 5\n",
    "kfold = KFold(n_folds, True, random_state=22)\n",
    "trains = []\n",
    "tests = []\n",
    "for train, test in kfold.split(data_real):\n",
    "    trains.append(np.array(data_real)[train])\n",
    "    tests.append(np.array(data_real)[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dict = {}\n",
    "val_scores_dict = {}\n",
    "n_estimators_dict = {}\n",
    "test_scores_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = range(5, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.array(val)\n",
    "val_en = np.array(val_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f77cc4a7aa4a3484d1a10682b9b059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Max depths:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acf857c14f54e9a9acad8951174380f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds... :   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dd0223ad1343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         model.fit(trains[i][:, :n_feats], trains[i][:, n_feats], verbose=False,\n\u001b[0m\u001b[1;32m     20\u001b[0m                    \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                    early_stopping_rounds=5)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[1;32m    817\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[1;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "mape_scores = []\n",
    "val_scores = []\n",
    "n_estimators = []\n",
    "\n",
    "for max_depth in tqdm(max_depths, \"Max depths: \"):\n",
    "    \n",
    "    scores_dict[max_depth] = []\n",
    "    val_scores_dict[max_depth] = []\n",
    "    n_estimators_dict[max_depth] = []\n",
    "    \n",
    "    for i in tqdm(range(len(trains)), \"Folds... \", leave=False):\n",
    "        model = LGBMRegressor(\n",
    "                max_depth=max_depth,\n",
    "                learning_rate=0.08,\n",
    "                n_estimators=3000,\n",
    "        )\n",
    "\n",
    "        model.fit(trains[i][:, :n_feats], trains[i][:, n_feats], verbose=False,\n",
    "                   eval_set=[(val[:, :n_feats], val_en)],\n",
    "                   early_stopping_rounds=5)\n",
    "        \n",
    "        scores.append(mean_squared_error(model.predict(tests[i][:, :n_feats]), tests[i][:, n_feats])**0.5)        \n",
    "        mape_scores.append(mean_absolute_percentage_error(model.predict(tests[i][:, :n_feats]), tests[i][:, n_feats]))\n",
    "        \n",
    "        val_scores.append(model.evals_result_['valid_0']['l2'][-1])#['validation_0']['rmse'][-1])\n",
    "        \n",
    "        n_estimators.append(len(model.evals_result_['valid_0']['l2']))#(model.best_ntree_limit)\n",
    "        n_estimators_dict[max_depth].append(len(model.evals_result_['valid_0']['l2']))#(model.best_ntree_limit)\n",
    "        \n",
    "        val_scores_dict[max_depth].append(model.evals_result_['valid_0']['l2'][-1])#['validation_0']['rmse'][-1])\n",
    "        scores_dict[max_depth].append(mean_squared_error(model.predict(tests[i][:, :n_feats]), tests[i][:, n_feats])**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = np.array(scores).reshape((len(max_depths), n_folds)).mean(axis=1)\n",
    "mape_scores_ = np.array(mape_scores).reshape((len(max_depths), n_folds)).mean(axis=1)\n",
    "\n",
    "scores_std = np.array(scores).reshape((len(max_depths), n_folds)).std(axis=1)\n",
    "mape_scores_std = np.array(mape_scores).reshape((len(max_depths), n_folds)).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores_ = np.array(val_scores).reshape((len(max_depths), n_folds)).mean(axis=1)\n",
    "val_scores_std = np.array(val_scores).reshape((len(max_depths), n_folds)).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_ = np.array(n_estimators).reshape((len(max_depths), n_folds)).mean(axis=1)\n",
    "n_estimators_std = np.array(n_estimators).reshape((len(max_depths), n_folds)).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([mape_scores_, mape_scores_std, scores_, \n",
    "                   scores_std, val_scores_, val_scores_std,\n",
    "                   n_estimators_, n_estimators_std]).T\n",
    "\n",
    "df.columns = ['mape_scores_', 'mape_scores_std', 'scores_',\n",
    "              'scores_std', 'val_scores_', 'val_scores_std',\n",
    "              'n_estimators_', 'n_estimators_std']\n",
    "\n",
    "df['max_depth'] = np.array(max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('grid_search_results_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('grid_search_results_lgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = df.scores_\n",
    "scores_std = df.scores_std\n",
    "\n",
    "mape_scores_ = df.mape_scores_\n",
    "mape_scores_std = df.mape_scores_std\n",
    "\n",
    "val_scores_ = df.val_scores_\n",
    "val_scores_std = df.val_scores_std\n",
    "\n",
    "n_estimators_ = df.n_estimators_\n",
    "n_estimators_std = df.n_estimators_std\n",
    "\n",
    "max_depths = df.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_max_depths = [str(max_depths[i]) for i in range(len(max_depths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drmse = (scores_.max()*100 - scores_.min()*100) / len(scores_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x = np.array(max_depths),\n",
    "                    y = n_estimators_, name = 'Number of trees',\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=scores_*200, color='darkblue', opacity=0.75)\n",
    "            ),\n",
    "                secondary_y=False)\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = np.array(max_depths),\n",
    "            y = np.array(scores_)*1000, mode='markers', name='RMSE', marker=dict(size=scores_*200, symbol=3,\n",
    "                                         color='darkred', opacity=0.75  \n",
    "                                                    )),\n",
    "        secondary_y=True)\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=n_estimators_, y=np.array(max_depths), mode='markers',\n",
    "#                                 text=scores_,  marker=dict(size=scores_*250,\n",
    "#                                          color=scores_,    \n",
    "#                                          colorscale='sunset_r'), ))\n",
    "        \n",
    "fig.update_xaxes(showline=True, title_text=\"Maximal depth of tree\", ticks='outside', mirror=True, linecolor='black')\n",
    "fig.update_yaxes(showline=True, title_text=\"Number of trees\", secondary_y=False, color = 'darkblue', tickmode = 'linear',\n",
    "        tick0 = 0,\n",
    "        dtick = 250, ticks='outside', mirror=True, linecolor='black')\n",
    "fig.update_yaxes(showline=True, title_text=\"RMSE, KeV\", secondary_y=True, color = 'darkred',\n",
    "        tickmode = 'array',\n",
    "        #tickvals = [8.600, 8.625, 8.650, 8.675, 8.700, 8.725, 8.750, 8.775, 8.800],\n",
    "                ticks='outside', mirror=True, linecolor='black', showgrid=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = 3,\n",
    "        dtick = 1\n",
    "    ),\n",
    "    legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"right\",\n",
    "    x=0.925,bordercolor=\"Black\",\n",
    "        borderwidth=1\n",
    "),\n",
    "    #legend=dict(\n",
    "    #orientation=\"h\",\n",
    "    #yanchor=\"bottom\",\n",
    "    #y=1.02,\n",
    "    #xanchor=\"right\",\n",
    "    #x=1),\n",
    "showlegend=True, font=dict(\n",
    "            size=15,))\n",
    "\n",
    "pio.write_image(fig, 'plots/BDT_grid_search_lgbm.pdf', width=950, height=600, scale=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x = np.array(max_depths),\n",
    "                    y = n_estimators_, name = 'Number of trees',\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=scores_*200, color='darkblue', opacity=0.75)\n",
    "            ),\n",
    "                secondary_y=False)\n",
    "\n",
    "fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = np.array(max_depths),\n",
    "            y = np.array(mape_scores_), mode='markers', name='MAPE', marker=dict(size=mape_scores_*15, symbol=3,\n",
    "                                         color='darkred', opacity=0.75  \n",
    "                                                    )),\n",
    "        secondary_y=True)\n",
    "\n",
    "fig.update_xaxes(showline=True, title_text=\"Maximal depth of tree\", ticks='outside', mirror=True, linecolor='black')\n",
    "fig.update_yaxes(showline=True, title_text=\"Number of trees\", secondary_y=False, color = 'darkblue',  tickmode = 'linear',\n",
    "        tick0 = 0,\n",
    "        dtick = 250, ticks='outside', mirror=True, linecolor='black')\n",
    "fig.update_yaxes(showline=True, title_text=\"MAPE\", secondary_y=True, color = 'darkred',\n",
    "        tickmode = 'array',\n",
    "        #tickvals = [8.600, 8.625, 8.650, 8.675, 8.700, 8.725, 8.750, 8.775, 8.800],\n",
    "                ticks='outside', mirror=True, linecolor='black', showgrid=False)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis = dict(\n",
    "        tickmode = 'linear',\n",
    "        tick0 = 3,\n",
    "        dtick = 1\n",
    "    ),\n",
    "    legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"right\",\n",
    "    x=0.925,bordercolor=\"Black\",\n",
    "        borderwidth=1\n",
    "),\n",
    "    #legend=dict(\n",
    "    #orientation=\"h\",\n",
    "    #yanchor=\"bottom\",\n",
    "    #y=1.02,\n",
    "    #xanchor=\"right\",\n",
    "    #x=1),\n",
    "showlegend=True, font=dict(\n",
    "            size=15,))\n",
    "\n",
    "pio.write_image(fig, 'plots/BDT_grid_search_mape_lgbm.pdf', width=950, height=600, scale=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
