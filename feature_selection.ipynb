{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e3d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c2513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "vm = input()\n",
    "if vm.lower()=='yes':\n",
    "    vm=True\n",
    "else:\n",
    "    vm=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f35928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "train_mode = input()\n",
    "if train_mode.lower()=='yes':\n",
    "    train_mode=True\n",
    "else:\n",
    "    train_mode=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc351142",
   "metadata": {},
   "outputs": [],
   "source": [
    "if vm:\n",
    "    path='/mnt/cephfs/ml_data/mc_2021/'\n",
    "else:\n",
    "    path=''\n",
    "    \n",
    "data_real = pd.read_csv('{}processed_data/ProcessedTrainReal/ProcessedTrain_1M.csv.gz'.format(path))\n",
    "data_real = data_real[data_real['edepR'] < 17.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ed7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a5c487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c265bbbc5f294bc5b1af3bb08d4572ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Folds... : 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "if train_mode:\n",
    "    size = int(1e6)\n",
    "    n_feats = len(data_real.columns) - 5\n",
    "    \n",
    "    X_val = np.array(data_real[size:])[:, :n_feats]\n",
    "    y_val = np.array(data_real[size:])[:, n_feats]\n",
    "    data_real = np.array(data_real)[:size]\n",
    "    \n",
    "    n_folds = 10\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    \n",
    "    kfold = KFold(n_folds, True, random_state=22)    \n",
    "    for train, test in tqdm(kfold.split(data_real), \"Folds... \", leave=False):        \n",
    "        xgbreg = XGBRegressor(\n",
    "                max_depth=9,\n",
    "                learning_rate=0.08,\n",
    "                n_estimators=3000,\n",
    "                n_jobs=10\n",
    "        )\n",
    "                            \n",
    "        X_train = data_real[train][:, :n_feats]\n",
    "        y_train = data_real[train][:, n_feats]\n",
    "                            \n",
    "        X_test = data_real[test][:, :n_feats]\n",
    "        y_test = data_real[test][:, n_feats]\n",
    "\n",
    "        xgbreg.fit(X_train, y_train,\n",
    "                   verbose=False,\n",
    "                   eval_set=[(X_val, y_val)],\n",
    "                   early_stopping_rounds=5)\n",
    "        \n",
    "        y_predict = xgbreg.predict(X_test)\n",
    "        rmse = mean_squared_error(y_predict, y_test)**0.5\n",
    "        mape = mean_absolute_percentage_error(y_predict, y_test)\n",
    "        rmse_scores.append(rmse)\n",
    "        mape_scores.append(mape)\n",
    "    \n",
    "    result = np.array([[np.mean(mape_scores), np.std(mape_scores)], [np.mean(rmse_scores), np.std(rmse_scores)]])\n",
    "    np.savez_compressed('feature_selection/all_features_metrics.npz', a=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59afb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_metric = np.load('feature_selection/all_features_metrics.npz', allow_pickle=True)['a'][0][0]\n",
    "eps = np.load('feature_selection/all_features_metric.npz', allow_pickle=True)['a'][0][1]\n",
    "\n",
    "opt_features = []\n",
    "current_metrics = []\n",
    "current_metric = 100\n",
    "\n",
    "features = data_real.iloc[:, :-5].columns\n",
    "while abs(all_features_metric - current_metric) > eps:\n",
    "    metrics = []\n",
    "    for feature in tqdm(features, \"Features loop\"):\n",
    "        xgbreg = XGBRegressor(\n",
    "            max_depth=9,\n",
    "            learning_rate=0.08,\n",
    "            n_estimators=3000,\n",
    "            random_state=22,\n",
    "        )\n",
    "        \n",
    "        scores = cross_val_score(\n",
    "            xgbreg,\n",
    "            data_real.iloc[:, :-5][opt_features+[feature]],\n",
    "            data_real.iloc[:, -5],\n",
    "            cv=5,\n",
    "            n_jobs=5,\n",
    "            verbose=100,\n",
    "            scoring='neg_mean_absolute_percentage_error'\n",
    "        )\n",
    "        \n",
    "        metric = -100*scores.mean()\n",
    "        metrics.append(metric)\n",
    "\n",
    "    best_metric_ind = np.argmin(metrics)\n",
    "    current_metric = metrics[best_metric_ind]\n",
    "    current_metrics.append(current_metric)\n",
    "    opt_features.append(features[best_metric_ind])\n",
    "    features = features.drop(features[best_metric_ind])\n",
    "\n",
    "    print(current_metrics)\n",
    "    print(opt_features)\n",
    "    \n",
    "    np.savez_compressed('feature_selection/opt_features.npz', a=np.array(opt_features))\n",
    "    np.savez_compressed('feature_selection/current_metrics.npz', a=np.array(current_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243051ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('feature_selection/opt_features.npz', a=np.array(opt_features))\n",
    "np.savez_compressed('feature_selection/current_metrics.npz', a=np.array(current_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a08ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
