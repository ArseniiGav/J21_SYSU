{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/arsde/J21SYSU/e/JSYSU-36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(JSYSU-36)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "\n",
    "neptune.init(\n",
    "    project_qualified_name='arsde/J21SYSU',\n",
    ")\n",
    "\n",
    "neptune.create_experiment()#'JSYSU-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSYSU-36\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def init(run_name):\n",
    "    os.system('mkdir {}'.format(run_name))\n",
    "    os.system('mkdir {}/models_saved'.format(run_name))\n",
    "    os.system('mkdir {}/results'.format(run_name))\n",
    "#     os.system('mkdir {}/preds'.format(run_name))\n",
    "    \n",
    "run_name = input()\n",
    "init(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2687819897926140535\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_J19 = pd.read_csv('../df_bdt_eval.csv')\n",
    "bdt_J19_5M_23 = bdt_J19[(bdt_J19['opt']==23) & (bdt_J19['model']=='5M')]\n",
    "bdt_J19_5M_0 = bdt_J19[(bdt_J19['opt']==0) & (bdt_J19['model']=='5M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/mnt/cephfs/ml_data/mc_2021/processed_data'\n",
    "data_real = pd.read_csv(f'{path}/ProcessedTrainReal/ProcessedTrain.csv.gz')\n",
    "data_real = data_real[data_real['edepR'] < 17.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_opt = ['AccumCharge', 'R_cht', 'z_cc', 'pe_std',\n",
    "#                 'nPMTs', 'ht_kurtosis', 'ht_25-20p', 'R_cc',\n",
    "#                 'ht_5-2p', 'pe_mean', 'jacob_cht', 'phi_cc',\n",
    "#                 'ht_35-30p', 'ht_20-15p', 'pe_35p', 'ht_30-25p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_opt = ['AccumCharge', 'nPMTs', 'R_cc', 'R_cht', 'pe_mean',\n",
    "                'pe_std', 'pe_skew', 'pe_kurtosis', 'pho_cc', 'pho_cht',\n",
    "                'ht_2p', 'ht_5p', 'ht_10p', 'ht_15p', 'ht_20p',\n",
    "                'ht_25p', 'ht_30p', 'ht_35p', 'ht_40p', 'ht_45p',\n",
    "                'ht_50p', 'ht_55p', 'ht_60p', 'ht_65p', 'ht_70p',\n",
    "                'ht_75p', 'ht_80p', 'ht_85p', 'ht_90p', 'ht_95p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [data_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = data_real.iloc[:, :-5][features_opt]\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "y = data_real['edep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4604438, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, concatenate, Input\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay, ExponentialDecay\n",
    "\n",
    "kernel_initializers = ['normal', 'lecun_normal', 'uniform', 'glorot_uniform']\n",
    "activations = ['relu', 'elu', 'selu']\n",
    "optimizers = ['adam', 'rmsprop', 'SGD']\n",
    "schedules = ['None', 'CosineDecay', 'ExponentialDecay']\n",
    "\n",
    "def build_model(hp):\n",
    "    fht_profile_input = Input(shape=(20, 1))\n",
    "    features_input = Input(shape=(10,))\n",
    "    \n",
    "    units_input = hp.Int('units_input', min_value=16, max_value=256, default=32, step=8)\n",
    "    units_in_hidden_layer = hp.Int('units_in_hidden_layer', min_value=16, max_value=256, default=32, step=8)\n",
    "    num_hidden_layers = hp.Int('num_hidden_layers', min_value=1, max_value=16, default=4, step=1)\n",
    "    kernel_initializer = hp.Choice('kernel_initializer', kernel_initializers)  \n",
    "\n",
    "    num_conv_layers = hp.Int('num_conv_layers', min_value=1, max_value=6, default=1, step=1)\n",
    "    num_filters = hp.Int('num_filters', min_value=1, max_value=8, default=1, step=1)\n",
    "    kernel_size = hp.Int('kernel_size', min_value=2, max_value=8, default=4, step=1)\n",
    "    kernel_initializer_conv = hp.Choice('kernel_initializer_conv', kernel_initializers)\n",
    "\n",
    "    activation_conv = hp.Choice('activation_conv', values=activations) \n",
    "    activation = hp.Choice('activation', values=activations)  \n",
    "    \n",
    "    optimizer = hp.Choice('optimizer', values=optimizers)\n",
    "    \n",
    "    lr = hp.Float('lr', min_value=1e-4, max_value=1e-2, default=1e-3, sampling='LOG')\n",
    "    decay_lr = hp.Choice('decay_lr', schedules)\n",
    "        \n",
    "    batch_norm_conv = hp.Choice('batch_norm_conv', [False, True])\n",
    "    batch_norm = hp.Choice('batch_norm', [False, True])\n",
    "       \n",
    "    if decay_lr == 'ExponentialDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=50, max_value=10000, default=200)\n",
    "        decay_rate = hp.Float('decay_rate', min_value=0.1, max_value=0.9, default=0.8)\n",
    "\n",
    "        lr = ExponentialDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate\n",
    "        )\n",
    "    elif decay_lr == 'CosineDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=50, max_value=10000, default=200)\n",
    "\n",
    "        lr = CosineDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "        )\n",
    "    \n",
    "    x = Conv1D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer=kernel_initializer_conv,\n",
    "               activation=activation_conv\n",
    "        )(fht_profile_input)\n",
    "    if batch_norm_conv:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    for i in range(num_conv_layers-1):\n",
    "        x = Conv1D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer=kernel_initializer_conv,\n",
    "               activation=activation_conv\n",
    "              )(x)\n",
    "        if batch_norm_conv:\n",
    "            x = BatchNormalization()(x)\n",
    "            \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(\n",
    "            units=20,\n",
    "            activation=activation,\n",
    "            kernel_initializer=kernel_initializer\n",
    "        )(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    \n",
    "    x = concatenate([x, features_input], axis=1)\n",
    "    x = Dense(units=units_input,\n",
    "              kernel_initializer=kernel_initializer,\n",
    "              activation=activation\n",
    "            )(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "        x = Dense(units=units_in_hidden_layer,\n",
    "                  kernel_initializer=kernel_initializer,\n",
    "                  activation=activation\n",
    "            )(x)\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "    output = Dense(units=1,\n",
    "                   kernel_initializer=kernel_initializer,\n",
    "                   activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=[fht_profile_input, features_input],\n",
    "                  outputs=output,\n",
    "                  name='Model')\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(lr)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(lr)\n",
    "    elif optimizer == 'SGD':\n",
    "        optimizer = SGD(lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "        metrics=[\n",
    "                tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "                'mse',\n",
    "                'mae'\n",
    "            ])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 20, 1)        5           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 20)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           420         flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30)           0           dense[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           992         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           1056        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           1056        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           1056        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           1056        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,674\n",
      "Trainable params: 5,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "from kerastuner.tuners import BayesianOptimization, Hyperband\n",
    "\n",
    "\n",
    "class MyTuner(BayesianOptimization):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 256, 2048, step=128)\n",
    "        super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "\n",
    "tuner = MyTuner(\n",
    "    build_model,\n",
    "    objective='val_mape',\n",
    "    max_trials=120,\n",
    "    seed=21,\n",
    "    directory='saved_networks',\n",
    "    project_name=run_name,\n",
    "    logger=npt_utils.NeptuneLogger()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_mape', patience=3, mode='min',\n",
    "        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fht = X[:, 10:30].reshape(-1, 20, 1)\n",
    "X_features = X[:, :10]\n",
    "\n",
    "X_input = [X_fht, X_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units_input       |56                |?                 \n",
      "units_in_hidden...|248               |?                 \n",
      "num_hidden_layers |15                |?                 \n",
      "kernel_initializer|glorot_uniform    |?                 \n",
      "num_conv_layers   |3                 |?                 \n",
      "num_filters       |6                 |?                 \n",
      "kernel_size       |6                 |?                 \n",
      "kernel_initiali...|normal            |?                 \n",
      "activation_conv   |selu              |?                 \n",
      "activation        |selu              |?                 \n",
      "optimizer         |adam              |?                 \n",
      "lr                |0.00014284        |?                 \n",
      "decay_lr          |ExponentialDecay  |?                 \n",
      "batch_norm_conv   |1                 |?                 \n",
      "batch_norm        |1                 |?                 \n",
      "\n",
      "Model: \"Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 20, 6)        42          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 20, 6)        24          conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 20, 6)        222         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20, 6)        24          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 20, 6)        222         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 20, 6)        24          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 120)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           2420        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 20)           80          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30)           0           batch_normalization_3[0][0]      \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 56)           1736        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56)           224         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 248)          14136       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 248)          992         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 248)          61752       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 248)          992         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 248)          61752       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 248)          992         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 248)          61752       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 248)          992         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 248)          61752       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 248)          992         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 248)          61752       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 248)          992         dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 248)          61752       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 248)          992         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 248)          61752       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 248)          992         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 248)          61752       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 248)          992         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 248)          61752       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 248)          992         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 248)          61752       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 248)          992         dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 248)          61752       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 248)          992         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 248)          61752       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 248)          992         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 248)          61752       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 248)          992         dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 248)          61752       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 248)          992         dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            249         batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 898,811\n",
      "Trainable params: 891,183\n",
      "Non-trainable params: 7,628\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16188/16188 - 1148s - loss: 37.2398 - mape: 37.2398 - mse: 94.5848 - mae: 3.6601 - val_loss: 34.7378 - val_mape: 34.7378 - val_mse: 95.8247 - val_mae: 3.4946\n",
      "Epoch 2/200\n",
      "16188/16188 - 1074s - loss: 35.1591 - mape: 35.1591 - mse: 93.4467 - mae: 3.4940 - val_loss: 34.7923 - val_mape: 34.7923 - val_mse: 95.6726 - val_mae: 3.4992\n",
      "Epoch 3/200\n",
      "16188/16188 - 1044s - loss: 35.1632 - mape: 35.1632 - mse: 93.4500 - mae: 3.4941 - val_loss: 34.1142 - val_mape: 34.1142 - val_mse: 93.4953 - val_mae: 3.4334\n",
      "Epoch 4/200\n",
      "16188/16188 - 1025s - loss: 35.1600 - mape: 35.1600 - mse: 93.4376 - mae: 3.4940 - val_loss: 33.6952 - val_mape: 33.6952 - val_mse: 92.5982 - val_mae: 3.3982\n",
      "Epoch 5/200\n",
      "16188/16188 - 1046s - loss: 35.1564 - mape: 35.1564 - mse: 93.4475 - mae: 3.4938 - val_loss: 34.5511 - val_mape: 34.5511 - val_mse: 95.3075 - val_mae: 3.4768\n",
      "Epoch 6/200\n",
      "16188/16188 - 1016s - loss: 35.1605 - mape: 35.1605 - mse: 93.4355 - mae: 3.4940 - val_loss: 35.3484 - val_mape: 35.3484 - val_mse: 97.7173 - val_mae: 3.5524\n",
      "Epoch 7/200\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_input,\n",
    "             y,\n",
    "#              batch_size=1024,\n",
    "             epochs=200, \n",
    "             validation_split=0.1,\n",
    "             callbacks=[monitor],\n",
    "             verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "model.save(\"{0}/models_saved/{0}.h5\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"{}/models_saved/fcdnn_real.h5\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "energies = [0, 0.1, 0.3, 0.6] + list(range(1, 11))\n",
    "y_true_array = []\n",
    "y_pred_array = []\n",
    "for j in tqdm(range(len(all_data)), \"Options...\", leave=False):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for energy in tqdm(energies, \"Energies...\", leave=False):\n",
    "        test = pd.read_csv(f'{path}/ProcessedTestReal/{energy}MeV.csv.gz')\n",
    "        test = test[test['edepR'] < 17.2]\n",
    "        edep = np.array(test['edep'])\n",
    "        X_test = test[features_opt]\n",
    "        X_test = scaler.transform(X_test)\n",
    "        X_test_fht = X_test[:, 10:30].reshape(-1, 20, 1)\n",
    "        X_test_features = X_test[:, :10]\n",
    "        X_test_input = [X_test_fht, X_test_features]\n",
    "        edep_preds = model.predict(X_test_input).flatten()\n",
    "        \n",
    "        y_true.append(edep)\n",
    "        y_pred.append(edep_preds)\n",
    "    y_true_array.append(y_true)\n",
    "    y_pred_array.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from eli5.permutation_importance import get_score_importances \n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# def score(X, y):\n",
    "#     y_pred = model.predict(X)\n",
    "#     return mean_squared_error(y, y_pred)\n",
    "\n",
    "# base_score, score_decreases = get_score_importances(score, X[:50000], y[:50000])\n",
    "# feature_importances = np.mean(score_decreases, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fi = dict(zip(features_opt, feature_importances))\n",
    "# fi = dict(sorted(fi.items(), key=lambda item: item[1]))\n",
    "# df_fi = pd.DataFrame.from_dict(fi, orient='index', columns=['Permutation Importance'])\n",
    "# df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptunecontrib.api import log_table\n",
    "# log_table('output/permutation_importance', df_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = np.array([\n",
    "    [y_pred_array[j][i] - y_true_array[j][i] for i in range(len(y_pred_array[0]))]\n",
    "    for j in range(len(y_pred_array))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Elecsim 5M Real', 'Detsim 5M Ideal', 'Detsim 5M Real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = [0, 0.1, 0.3, 0.6] + list(range(1, 11))\n",
    "energies = np.array([1.022+i for i in energies]).round(5)\n",
    "energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a_array = []\n",
    "errors_array = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    a = []\n",
    "    e = []\n",
    "    for i in range(diffs.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        nbins = 150\n",
    "        n, bins, patches = ax.hist(diffs[k][i], nbins, density=True, facecolor = 'grey', alpha = 0.5, label='before');\n",
    "        plt.close(fig)\n",
    "        centers = (0.5*(bins[1:]+bins[:-1]))\n",
    "        pars, cov = curve_fit(lambda x, mu, sig : norm.pdf(x, loc=mu, scale=sig), centers, n, p0=[0,1])  \n",
    "        a.append(pars)\n",
    "        e.append(cov)\n",
    "    a_array.append(a)\n",
    "    errors_array.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from neptunecontrib.api import log_chart\n",
    "\n",
    "for k in range(len(all_data)):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        x = np.linspace(diffs[k][i][:35000].min(), diffs[k][i][:35000].max(), 100)\n",
    "        p = stats.norm.pdf(x, a_array[k][i][0], a_array[k][i][1])\n",
    "\n",
    "        fig.add_trace(go.Scattergl(x=x,\n",
    "                     y=p, mode='lines', name='mu={:.3f} +- {:.3f}, sigma={:.3f} +- {:.3f}'.format(\n",
    "                         a_array[k][i][0], np.sqrt(errors_array[k][i][0][0]),\n",
    "                         a_array[k][i][1], np.sqrt(errors_array[k][i][1][1])),\n",
    "                        visible = (i==0)\n",
    "                    ))\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        fig.add_trace(go.Histogram(x=diffs[k][i][:35000], xbins=dict(size=0.005),\n",
    "                      showlegend=False, histnorm='probability density',\n",
    "                     visible = (i==0)\n",
    "                    ))\n",
    "\n",
    "    buttons = []\n",
    "    for N in range(0, len(diffs[k])): \n",
    "        buttons.append(\n",
    "            dict(\n",
    "                 args=['visible', [False]*N + [True] + [False]*(len(diffs[k])-1-N)],\n",
    "                     label='Energy =  {} MeV'.format(energies[N]),\n",
    "                 method='restyle'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "\n",
    "        xaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "        ),\n",
    "\n",
    "        yaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            tick0=0,\n",
    "#             dtick=1,\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='black',\n",
    "            zerolinewidth=0.25\n",
    "            ),\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = '{}'.format(names[k]),\n",
    "        xaxis_title=r\"$$E_{rec} - E_{true}$$\",\n",
    "        showlegend=True,\n",
    "        updatemenus=list([\n",
    "            dict(\n",
    "                x=0.5,\n",
    "                y=1.2,\n",
    "                yanchor='top',\n",
    "                buttons=buttons\n",
    "            ),\n",
    "        ]),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.05,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    log_chart('output/Result_distributions.pdf', fig)\n",
    "#     run['output/Result_distributions.pdf'].upload(File.as_html(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(appr=False):\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                        row_width=[0.25, 0.75]\n",
    "    )\n",
    "\n",
    "    for k in range(diffs.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=res[k],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                showlegend=True,\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    width=10,\n",
    "                    array=error_sigma[k],\n",
    "                    visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=bias[k],\n",
    "                mode='markers',\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                error_y=dict(\n",
    "                        type='data',\n",
    "                        width=10,\n",
    "                        array=error_mu[k],\n",
    "                        visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=2, col=1\n",
    "        )\n",
    "\n",
    "    if appr:\n",
    "        for k in range(len(names)):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_lin,\n",
    "                    y=func(x_lin, a[k], b[k], c[k]),\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                    ),\n",
    "                    opacity=0.5,\n",
    "                    showlegend=False,\n",
    "                    name=names[k],\n",
    "                    marker=dict(\n",
    "                        color=colors[k]\n",
    "                    )\n",
    "                ), row=1, col=1\n",
    "            )\n",
    "\n",
    "    trace = lambda x, y, error_y, col, name, sym, leg=True: go.Scatter(\n",
    "                        x=x,\n",
    "                        y=100*y,\n",
    "                        mode='markers',\n",
    "                        name=name,\n",
    "                        showlegend=leg,\n",
    "                        marker=dict(\n",
    "                            color=col,\n",
    "                            symbol=sym\n",
    "                        ),\n",
    "                        error_y=dict(\n",
    "                            type='data',\n",
    "                            width=10,\n",
    "                            array=100*error_y\n",
    "                        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_0.energy+1.022,\n",
    "            bdt_J19_5M_0.res,\n",
    "            bdt_J19_5M_0.res_err,\n",
    "            'blue',\n",
    "            'Detsim 5M Ideal',\n",
    "            'square',\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_23.energy+1.022,\n",
    "            bdt_J19_5M_23.res,\n",
    "            bdt_J19_5M_23.res_err,\n",
    "            'green',\n",
    "            'Detsim 5M Real',\n",
    "            'cross-open-dot',\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_0.energy+1.022,\n",
    "            bdt_J19_5M_0.bias,\n",
    "            bdt_J19_5M_0.bias_err,\n",
    "            'blue',\n",
    "            'Detsim 5M Ideal',\n",
    "            'square',\n",
    "            False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_23.energy+1.022,\n",
    "            bdt_J19_5M_23.bias,\n",
    "            bdt_J19_5M_23.bias_err,\n",
    "            'green',\n",
    "            'Detsim 5M Real',\n",
    "            'cross-open-dot',\n",
    "            False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    xaxis = dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        tick0=1,\n",
    "        dtick=1,\n",
    "        linecolor='black',\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "    )\n",
    "\n",
    "    yaxis = lambda range: dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        linecolor='black',\n",
    "        range=range,\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "        zeroline=True,\n",
    "        zerolinecolor='black',\n",
    "        zerolinewidth=0.25\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis2_title=\"Visible energy, MeV\",\n",
    "        yaxis1_title=\"Resolution, %\",\n",
    "        yaxis2_title=\"Bias, %\",\n",
    "\n",
    "        xaxis1 = xaxis,\n",
    "        xaxis2 = xaxis,\n",
    "        yaxis1 = yaxis([0, 3.5]),\n",
    "        yaxis2 = yaxis([-0.25, 0.25]),\n",
    "\n",
    "        showlegend=True,\n",
    "        font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=0.75,\n",
    "            y=0.99,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    if appr:\n",
    "        pio.write_image(fig, '{}/results/appr_results.pdf'.format(run_name), width=900, height=600)\n",
    "        log_chart('{}/results/appr_results.pdf'.format(run_name), fig)\n",
    "#         run['output/appr_results.pdf'].upload(File.as_html(fig))\n",
    "    else:\n",
    "        pio.write_image(fig, '{}/results/results.pdf'.format(run_name), width=900, height=600)\n",
    "        log_chart('{}/results/results.pdf'.format(run_name), fig)\n",
    "#         run['output/results.pdf'].upload(File.as_html(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'blue', 'green']\n",
    "symbols = ['star-square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_sigma = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][1][1]) / energies[i] for i in range(len(energies))]\n",
    "    error_sigma.append(error)\n",
    "    \n",
    "error_mu = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][0][0]) / energies[i] for i in range(len(energies))]\n",
    "    error_mu.append(error)\n",
    "\n",
    "res = []\n",
    "bias = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    sigma = [100 * a_array[k][i][1] / energies[i] for i in range(len(energies))]\n",
    "    mu = [100 * a_array[k][i][0] / energies[i] for i in range(len(energies))]\n",
    "    res.append(sigma)\n",
    "    bias.append(mu)\n",
    "    \n",
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x, a):\n",
    "    return np.sqrt((a/x**0.5)**2)\n",
    "\n",
    "\n",
    "def b(x, b):\n",
    "    b_list = []\n",
    "    b_list.append(np.sqrt(b**2))\n",
    "    return b_list*len(x)\n",
    "\n",
    "\n",
    "def c(x, c):\n",
    "    return np.sqrt((c/x)**2)\n",
    "\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return np.sqrt((a/x**0.5)**2 + b**2 + (c/x)**2) \n",
    "\n",
    "\n",
    "def approximated(x, y, yerr):\n",
    "    popt, pcov = curve_fit(func, x, y, sigma=yerr, maxfev=10**9, bounds=([0, 0, 0], [5, 5, 5]))\n",
    "    a, b, c = popt\n",
    "    #perr = np.sqrt(abs(pcov.diagonal()))\n",
    "\n",
    "    return func(x, a, b, c), popt, pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "y_approximated_array = []\n",
    "coefs_array = []\n",
    "errors_array = []\n",
    "corr_matrixes = []\n",
    "for i in range(diffs.shape[0]):\n",
    "    y_approximated, coefs, pcov = approximated(\n",
    "        energies[1:13], res[i][1:13], error_sigma[i][1:13])\n",
    "    y_approximated_array.append(y_approximated)\n",
    "    coefs_array.append(coefs)\n",
    "    errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "    corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "y_approximated, coefs, pcov = approximated(\n",
    "    bdt_J19_5M_0.energy+1.022, 100*bdt_J19_5M_0.res, 100*bdt_J19_5M_0.res_err)\n",
    "y_approximated_array.append(y_approximated)\n",
    "coefs_array.append(coefs)\n",
    "errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "y_approximated, coefs, pcov = approximated(\n",
    "    bdt_J19_5M_23.energy+1.022, 100*bdt_J19_5M_23.res, 100*bdt_J19_5M_23.res_err)\n",
    "y_approximated_array.append(y_approximated)\n",
    "coefs_array.append(coefs)\n",
    "errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "corr_matrixes = np.array(corr_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [0, 3, 1, 4, 2, 5]\n",
    "coefs_df = pd.DataFrame(\n",
    "    np.hstack((coefs_array, errors_array))\n",
    ")[reindex]\n",
    "coefs_df.columns = ['a', r'$\\Delta a$', 'b', r'$\\Delta b$', 'c', r'$\\Delta c$']\n",
    "\n",
    "a = np.array(coefs_array).T[0]\n",
    "b = np.array(coefs_array).T[1]\n",
    "c = np.array(coefs_array).T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = np.linspace(0.8, 11.5, 1000)\n",
    "plot_results(appr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The JUNO collaboration., Abusleme, A., Adam, T. et al. Calibration strategy of the JUNO experiment. J. High Energ. Phys. 2021, 4 (2021). https://doi.org/10.1007/JHEP03(2021)004**\n",
    "\n",
    "It was found, numerically, that the JUNO baseline requirement to determine the MO to 3 â€“ 4 $\\sigma$ significance could be translated into a convenient requirement on an effective resolution $\\tilde{a}$ as:\n",
    "\n",
    "$$\\tilde{a} \\equiv \\sqrt{(a)^2 + (1.6 \\times b)^2 + \\left(\\frac{c}{1.6}\\right)^2} \\leq 3\\%$$\n",
    "\n",
    "Let's calculate the variance as follows:\n",
    "\n",
    "$$\\Delta \\tilde{a}^2 = \\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\Delta a \\right)^2 +\n",
    "                       \\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\Delta b \\right)^2 +\n",
    "                       \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\Delta c \\right)^2 +\n",
    "2 \\left[\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\right) r_{ab} \\Delta a \\Delta b +\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\right) r_{ac} \\Delta a \\Delta c +\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\right) r_{bc} \\Delta b \\Delta c\n",
    "\\right]$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\Delta \\tilde{a}^2 = \\frac{\\left(a\\Delta a\\right)^2 + \\left(2.56\\times b\\Delta b\\right)^2 + \\left(\\frac{c\\Delta c}{2.56}\\right)^2}{\\tilde{a}^2} + 2 \\left[\n",
    "\\frac{2.56ab}{\\tilde{a}^2} r_{ab} \\Delta a \\Delta b +\n",
    "\\frac{ac}{2.56\\tilde{a}^2} r_{ac} \\Delta a \\Delta c +\n",
    "\\frac{bc}{\\tilde{a}^2} r_{bc} \\Delta b \\Delta c\n",
    "\\right] = \n",
    "\\frac{1}{\\tilde{a}^2} \\left[\n",
    "\\left(a\\Delta a\\right)^2 + \\left(2.56\\times b\\Delta b\\right)^2 + \\left(\\frac{c\\Delta c}{2.56}\\right)^2 +\n",
    "5.12 a b r_{ab} \\Delta a \\Delta b + \n",
    "\\frac{ac}{1.28} r_{ac} \\Delta a \\Delta c +\n",
    "2bcr_{bc} \\Delta b \\Delta c\n",
    "\\right]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = coefs_df.round(3)\n",
    "coefs_df.index = names\n",
    "coefs_df[r'$\\tilde{a}$'] = (coefs_df['a']**2 + (1.6 * coefs_df['b'])**2 + (coefs_df['c'] / 1.6)**2)**0.5 \n",
    "coefs_df[r'$\\Delta \\tilde{a}$'] = np.sqrt( (coefs_df['a']*coefs_df[r'$\\Delta a$'])**2 + \\\n",
    "                                           (2.56*coefs_df['b']*coefs_df[r'$\\Delta b$'])**2 + \\\n",
    "                                           (coefs_df['c']*coefs_df[r'$\\Delta c$'] / 2.56)**2) / coefs_df[r'$\\tilde{a}$']\n",
    "\n",
    "coefs_df[r'$\\Delta \\tilde{a}$'] = np.sqrt(\n",
    "    coefs_df[r'$\\Delta \\tilde{a}$']**2 + 2 * (\n",
    "        1.6**2 * coefs_df['a'] * coefs_df['b'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 0, 1] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta b$'] +\\\n",
    "        \n",
    "        coefs_df['a'] * coefs_df['c'] / (coefs_df[r'$\\tilde{a}$']**2 * 1.6**2) *\\\n",
    "        corr_matrixes[:, 0, 2] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta c$'] +\\\n",
    "\n",
    "        coefs_df['b'] * coefs_df['c'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 1, 2] * coefs_df[r'$\\Delta b$'] * coefs_df[r'$\\Delta c$']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run['output/coefs_df'].upload(File.as_html(coefs_df))\n",
    "log_table('output/coefs_df', coefs_df)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune import log_metric\n",
    "log_metric('a_tilde', coefs_df[r'$\\tilde{a}$']['Elecsim 5M Real'])\n",
    "log_metric('a_tilde_std', coefs_df[r'$\\Delta \\tilde{a}$']['Elecsim 5M Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df.reset_index().to_csv('{}/results/params.csv'.format(run_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "neptune": {
   "notebookId": "398ccb38-2583-4296-887f-cfee13a48e82",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
