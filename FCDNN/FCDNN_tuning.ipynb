{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): Driver Not Loaded. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/arsde/J21SYSU/e/JSYSU-67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(JSYSU-67)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "\n",
    "neptune.init(\n",
    "    project_qualified_name='arsde/J21SYSU',\n",
    ")\n",
    "\n",
    "neptune.create_experiment()#'JSYSU-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSYSU-67\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def init(run_name):\n",
    "    os.system('mkdir {}'.format(run_name))\n",
    "    os.system('mkdir {}/models_saved'.format(run_name))\n",
    "    os.system('mkdir {}/results'.format(run_name))\n",
    "#     os.system('mkdir {}/preds'.format(run_name))\n",
    "    \n",
    "run_name = input()\n",
    "init(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17579420690435562310\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_J19 = pd.read_csv('../df_bdt_eval.csv')\n",
    "bdt_J19_5M_23 = bdt_J19[(bdt_J19['opt']==23) & (bdt_J19['model']=='5M')]\n",
    "bdt_J19_5M_0 = bdt_J19[(bdt_J19['opt']==0) & (bdt_J19['model']=='5M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/mnt/cephfs/ml_data/mc_2021/processed_data'\n",
    "data_real = pd.read_csv(f'{path}/ProcessedTrainReal/ProcessedTrain.csv.gz')\n",
    "data_real = data_real[data_real['edepR'] < 17.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_opt = ['AccumCharge', 'nPMTs', 'R_cc', 'R_cht', 'pe_mean',\n",
    "                'pe_std', 'pe_skew', 'pe_kurtosis', 'pho_cc', 'pho_cht',\n",
    "                'ht_2p', 'ht_5p', 'ht_10p', 'ht_15p', 'ht_20p',\n",
    "                'ht_25p', 'ht_30p', 'ht_35p', 'ht_40p', 'ht_45p',\n",
    "                'ht_50p', 'ht_55p', 'ht_60p', 'ht_65p', 'ht_70p',\n",
    "                'ht_75p', 'ht_80p', 'ht_85p', 'ht_90p', 'ht_95p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [data_real]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = data_real.iloc[:, :-5][features_opt]\n",
    "scaler.fit(X)\n",
    "\n",
    "X = scaler.transform(X)\n",
    "y = data_real['edep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4604438, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, concatenate, Input\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay, ExponentialDecay\n",
    "\n",
    "kernel_initializer_input = ['normal'] #['normal', 'lecun_normal', 'uniform']\n",
    "kernel_initializer_hidden = ['normal'] #['normal', 'lecun_normal', 'uniform']\n",
    "activations = ['relu'] #['relu', 'elu', 'selu']\n",
    "optimizers = ['SGD'] # ['adam', 'rmsprop', 'SGD']\n",
    "schedules = ['None', 'ExponentialDecay']\n",
    "units_input_list = [256] # [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "units_in_hidden_layer_list = [256] # [1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "num_hidden_layers_list = [16] # [1, 2, 4, 8, 16, 32]\n",
    "\n",
    "def build_model(hp):\n",
    "    input_features = Input(shape=X.shape[1])\n",
    "    \n",
    "#     units_input = hp.Int('units_input', min_value=16, max_value=256, default=32, step=8)\n",
    "#     units_in_hidden_layer = hp.Int('units_in_hidden_layer', min_value=16, max_value=256, default=32, step=8)\n",
    "#     num_hidden_layers = hp.Int('num_hidden_layers', min_value=1, max_value=16, default=2, step=1)\n",
    "\n",
    "    units_input = hp.Choice('units_input', units_input_list, default=256)\n",
    "    units_in_hidden_layer = hp.Choice('units_in_hidden_layer', units_in_hidden_layer_list, default=256)\n",
    "    num_hidden_layers = hp.Choice('num_hidden_layers', num_hidden_layers_list, default=16)\n",
    "    kernel_initializers_input = hp.Choice('kernel_initializers_input', kernel_initializer_input)  \n",
    "    kernel_initializers_hidden = hp.Choice('kernel_initializers_hidden', kernel_initializer_hidden)\n",
    "    activation = hp.Choice('activation', values=activations)      \n",
    "    optimizer = hp.Choice('optimizer', values=optimizers)\n",
    "    \n",
    "    lr = hp.Float('lr', min_value=1e-4, max_value=1e-2, default=1e-3, sampling='LOG')\n",
    "    decay_lr = hp.Choice('decay_lr', schedules)\n",
    "        \n",
    "#     batch_norm = hp.Choice('batch_norm', [False, True])\n",
    "       \n",
    "    if decay_lr == 'ExponentialDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=500, max_value=20000, default=2000)\n",
    "        decay_rate = hp.Float('decay_rate', min_value=0.1, max_value=0.9, default=0.8)\n",
    "\n",
    "        lr = ExponentialDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate\n",
    "        )\n",
    "    elif decay_lr == 'CosineDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=500, max_value=20000, default=2000)\n",
    "\n",
    "        lr = CosineDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "        )\n",
    "\n",
    "    x = Dense(units=units_input,\n",
    "              kernel_initializer=kernel_initializers_input,\n",
    "              activation=activation\n",
    "            )(input_features)\n",
    "#     if batch_norm:\n",
    "#         x = BatchNormalization()(x)\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "        x = Dense(units=units_in_hidden_layer,\n",
    "                  kernel_initializer=kernel_initializers_hidden,\n",
    "                  activation=activation\n",
    "            )(x)\n",
    "#         if batch_norm:\n",
    "#             x = BatchNormalization()(x)\n",
    "\n",
    "    output = Dense(units=1,\n",
    "                   kernel_initializer=\"normal\",\n",
    "                   activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_features,\n",
    "                  outputs=output,\n",
    "                  name='Model')\n",
    "\n",
    "#     if optimizer == 'adam':\n",
    "#         beta_1 = hp.Float('beta_1', min_value=0.01, max_value=1, default=0.9)\n",
    "#         beta_2 = hp.Float('beta_2', min_value=0.01, max_value=1, default=0.999)\n",
    "#         optimizer = Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "#     elif optimizer == 'rmsprop':\n",
    "#         rho = hp.Float('rho', min_value=0.01, max_value=1, default=0.9)\n",
    "#         momentum = hp.Float('momentum', min_value=0.0, max_value=1, default=0.9)\n",
    "#         optimizer = RMSprop(learning_rate=lr, rho=rho, momentum=momentum)\n",
    "#     elif optimizer == 'SGD':\n",
    "    momentum = hp.Float('momentum', min_value=0.0, max_value=1, default=0.9)\n",
    "    nesterov = hp.Boolean('nesterov', default=True)\n",
    "    optimizer = SGD(learning_rate=lr, momentum=momentum, nesterov=nesterov)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "        metrics=[\n",
    "                tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "                'mse',\n",
    "                'mae'\n",
    "            ])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7525\n",
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,060,865\n",
      "Trainable params: 1,060,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "from kerastuner.tuners import BayesianOptimization, Hyperband\n",
    "\n",
    "\n",
    "# class MyTuner(BayesianOptimization):\n",
    "#     def run_trial(self, trial, *args, **kwargs):\n",
    "#         kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 256, 2048, step=128)\n",
    "#         super(MyTuner, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "seed = np.random.randint(10000)\n",
    "print(seed)\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_mape',\n",
    "    max_trials=60,\n",
    "    seed=seed,\n",
    "    directory='saved_networks',\n",
    "    project_name=run_name,\n",
    "    logger=npt_utils.NeptuneLogger()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_mape', patience=5, mode='min',\n",
    "        restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units_input       |256               |?                 \n",
      "units_in_hidden...|256               |?                 \n",
      "num_hidden_layers |16                |?                 \n",
      "kernel_initiali...|normal            |?                 \n",
      "kernel_initiali...|normal            |?                 \n",
      "activation        |relu              |?                 \n",
      "optimizer         |SGD               |?                 \n",
      "lr                |0.0001058         |?                 \n",
      "decay_lr          |None              |?                 \n",
      "momentum          |0.48856           |?                 \n",
      "nesterov          |True              |?                 \n",
      "\n",
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,060,865\n",
      "Trainable params: 1,060,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X,\n",
    "             y,\n",
    "             batch_size=1024,\n",
    "             epochs=200, \n",
    "             validation_split=0.1,\n",
    "             callbacks=[monitor],\n",
    "             verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "model.save(\"{0}/models_saved/{0}.h5\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"{}/models_saved/fcdnn_real.h5\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "energies = [0, 0.1, 0.3, 0.6] + list(range(1, 11))\n",
    "y_true_array = []\n",
    "y_pred_array = []\n",
    "for j in tqdm(range(len(all_data)), \"Options...\", leave=False):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for energy in tqdm(energies, \"Energies...\", leave=False):\n",
    "        test = pd.read_csv('{}/ProcessedTestReal/{}MeV.csv.gz'.format(path, energy))\n",
    "        test = test[test['edepR'] < 17.2]\n",
    "        edep = np.array(test['edep'])\n",
    "        X_test = test[features_opt]\n",
    "        X_test = scaler.transform(X_test)\n",
    "        edep_preds = model.predict(X_test).flatten()\n",
    "        \n",
    "        y_true.append(edep)\n",
    "        y_pred.append(edep_preds)\n",
    "    y_true_array.append(y_true)\n",
    "    y_pred_array.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.permutation_importance import get_score_importances \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def score(X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return mean_squared_error(y, y_pred)\n",
    "\n",
    "base_score, score_decreases = get_score_importances(score, X[:50000], y[:50000])\n",
    "feature_importances = np.mean(score_decreases, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fi = dict(zip(features_opt, feature_importances))\n",
    "fi = dict(sorted(fi.items(), key=lambda item: item[1]))\n",
    "df_fi = pd.DataFrame.from_dict(fi, orient='index', columns=['Permutation Importance'])\n",
    "df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptunecontrib.api import log_table\n",
    "log_table('output/permutation_importance', df_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = np.array([\n",
    "    [y_pred_array[j][i] - y_true_array[j][i] for i in range(len(y_pred_array[0]))]\n",
    "    for j in range(len(y_pred_array))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Elecsim 5M Real', 'Detsim 5M Ideal', 'Detsim 5M Real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = [0, 0.1, 0.3, 0.6] + list(range(1, 11))\n",
    "energies = np.array([1.022+i for i in energies]).round(5)\n",
    "energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a_array = []\n",
    "errors_array = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    a = []\n",
    "    e = []\n",
    "    for i in range(diffs.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        nbins = 150\n",
    "        n, bins, patches = ax.hist(diffs[k][i], nbins, density=True, facecolor = 'grey', alpha = 0.5, label='before');\n",
    "        plt.close(fig)\n",
    "        centers = (0.5*(bins[1:]+bins[:-1]))\n",
    "        pars, cov = curve_fit(lambda x, mu, sig : norm.pdf(x, loc=mu, scale=sig), centers, n, p0=[0,1])  \n",
    "        a.append(pars)\n",
    "        e.append(cov)\n",
    "    a_array.append(a)\n",
    "    errors_array.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from neptunecontrib.api import log_chart\n",
    "\n",
    "for k in range(len(all_data)):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        x = np.linspace(diffs[k][i][:35000].min(), diffs[k][i][:35000].max(), 100)\n",
    "        p = stats.norm.pdf(x, a_array[k][i][0], a_array[k][i][1])\n",
    "\n",
    "        fig.add_trace(go.Scattergl(x=x,\n",
    "                     y=p, mode='lines', name='mu={:.3f} +- {:.3f}, sigma={:.3f} +- {:.3f}'.format(\n",
    "                         a_array[k][i][0], np.sqrt(errors_array[k][i][0][0]),\n",
    "                         a_array[k][i][1], np.sqrt(errors_array[k][i][1][1])),\n",
    "                        visible = (i==0)\n",
    "                    ))\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        fig.add_trace(go.Histogram(x=diffs[k][i][:35000], xbins=dict(size=0.005),\n",
    "                      showlegend=False, histnorm='probability density',\n",
    "                     visible = (i==0)\n",
    "                    ))\n",
    "\n",
    "    buttons = []\n",
    "    for N in range(0, len(diffs[k])): \n",
    "        buttons.append(\n",
    "            dict(\n",
    "                 args=['visible', [False]*N + [True] + [False]*(len(diffs[k])-1-N)],\n",
    "                     label='Energy =  {} MeV'.format(energies[N]),\n",
    "                 method='restyle'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    fig.update_layout(\n",
    "\n",
    "        xaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "        ),\n",
    "\n",
    "        yaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            tick0=0,\n",
    "#             dtick=1,\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='black',\n",
    "            zerolinewidth=0.25\n",
    "            ),\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = '{}'.format(names[k]),\n",
    "        xaxis_title=r\"$$E_{rec} - E_{true}$$\",\n",
    "        showlegend=True,\n",
    "        updatemenus=list([\n",
    "            dict(\n",
    "                x=0.5,\n",
    "                y=1.2,\n",
    "                yanchor='top',\n",
    "                buttons=buttons\n",
    "            ),\n",
    "        ]),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.05,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    log_chart('output/Result_distributions.pdf', fig)\n",
    "#     run['output/Result_distributions.pdf'].upload(File.as_html(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(appr=False):\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                        row_width=[0.25, 0.75]\n",
    "    )\n",
    "\n",
    "    for k in range(diffs.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=res[k],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                showlegend=True,\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    width=10,\n",
    "                    array=error_sigma[k],\n",
    "                    visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=bias[k],\n",
    "                mode='markers',\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                error_y=dict(\n",
    "                        type='data',\n",
    "                        width=10,\n",
    "                        array=error_mu[k],\n",
    "                        visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=2, col=1\n",
    "        )\n",
    "\n",
    "    if appr:\n",
    "        for k in range(len(names)):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_lin,\n",
    "                    y=func(x_lin, a[k], b[k], c[k]),\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                    ),\n",
    "                    opacity=0.5,\n",
    "                    showlegend=False,\n",
    "                    name=names[k],\n",
    "                    marker=dict(\n",
    "                        color=colors[k]\n",
    "                    )\n",
    "                ), row=1, col=1\n",
    "            )\n",
    "\n",
    "    trace = lambda x, y, error_y, col, name, sym, leg=True: go.Scatter(\n",
    "                        x=x,\n",
    "                        y=100*y,\n",
    "                        mode='markers',\n",
    "                        name=name,\n",
    "                        showlegend=leg,\n",
    "                        marker=dict(\n",
    "                            color=col,\n",
    "                            symbol=sym\n",
    "                        ),\n",
    "                        error_y=dict(\n",
    "                            type='data',\n",
    "                            width=10,\n",
    "                            array=100*error_y\n",
    "                        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_0.energy+1.022,\n",
    "            bdt_J19_5M_0.res,\n",
    "            bdt_J19_5M_0.res_err,\n",
    "            'blue',\n",
    "            'Detsim 5M Ideal',\n",
    "            'square',\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_23.energy+1.022,\n",
    "            bdt_J19_5M_23.res,\n",
    "            bdt_J19_5M_23.res_err,\n",
    "            'green',\n",
    "            'Detsim 5M Real',\n",
    "            'cross-open-dot',\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_0.energy+1.022,\n",
    "            bdt_J19_5M_0.bias,\n",
    "            bdt_J19_5M_0.bias_err,\n",
    "            'blue',\n",
    "            'Detsim 5M Ideal',\n",
    "            'square',\n",
    "            False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        trace(\n",
    "            bdt_J19_5M_23.energy+1.022,\n",
    "            bdt_J19_5M_23.bias,\n",
    "            bdt_J19_5M_23.bias_err,\n",
    "            'green',\n",
    "            'Detsim 5M Real',\n",
    "            'cross-open-dot',\n",
    "            False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    xaxis = dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        tick0=1,\n",
    "        dtick=1,\n",
    "        linecolor='black',\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "    )\n",
    "\n",
    "    yaxis = lambda range: dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        linecolor='black',\n",
    "        range=range,\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "        zeroline=True,\n",
    "        zerolinecolor='black',\n",
    "        zerolinewidth=0.25\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis2_title=\"Visible energy, MeV\",\n",
    "        yaxis1_title=\"Resolution, %\",\n",
    "        yaxis2_title=\"Bias, %\",\n",
    "\n",
    "        xaxis1 = xaxis,\n",
    "        xaxis2 = xaxis,\n",
    "        yaxis1 = yaxis([0, 3.5]),\n",
    "        yaxis2 = yaxis([-0.25, 0.25]),\n",
    "\n",
    "        showlegend=True,\n",
    "        font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=0.75,\n",
    "            y=0.99,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    if appr:\n",
    "        pio.write_image(fig, '{}/results/appr_results.pdf'.format(run_name), width=900, height=600)\n",
    "        log_chart('{}/results/appr_results.pdf'.format(run_name), fig)\n",
    "#         run['output/appr_results.pdf'].upload(File.as_html(fig))\n",
    "    else:\n",
    "        pio.write_image(fig, '{}/results/results.pdf'.format(run_name), width=900, height=600)\n",
    "        log_chart('{}/results/results.pdf'.format(run_name), fig)\n",
    "#         run['output/results.pdf'].upload(File.as_html(fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['darkviolet', 'blue', 'green']\n",
    "symbols = ['star-square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "error_sigma = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][1][1]) / energies[i] for i in range(len(energies))]\n",
    "    error_sigma.append(error)\n",
    "    \n",
    "error_mu = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][0][0]) / energies[i] for i in range(len(energies))]\n",
    "    error_mu.append(error)\n",
    "\n",
    "res = []\n",
    "bias = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    sigma = [100 * a_array[k][i][1] / energies[i] for i in range(len(energies))]\n",
    "    mu = [100 * a_array[k][i][0] / energies[i] for i in range(len(energies))]\n",
    "    res.append(sigma)\n",
    "    bias.append(mu)\n",
    "    \n",
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x, a):\n",
    "    return np.sqrt((a/x**0.5)**2)\n",
    "\n",
    "\n",
    "def b(x, b):\n",
    "    b_list = []\n",
    "    b_list.append(np.sqrt(b**2))\n",
    "    return b_list*len(x)\n",
    "\n",
    "\n",
    "def c(x, c):\n",
    "    return np.sqrt((c/x)**2)\n",
    "\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return np.sqrt((a/x**0.5)**2 + b**2 + (c/x)**2) \n",
    "\n",
    "\n",
    "def approximated(x, y, yerr):\n",
    "    popt, pcov = curve_fit(func, x, y, sigma=yerr, maxfev=10**9, bounds=([0, 0, 0], [5, 5, 5]))\n",
    "    a, b, c = popt\n",
    "    #perr = np.sqrt(abs(pcov.diagonal()))\n",
    "\n",
    "    return func(x, a, b, c), popt, pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "y_approximated_array = []\n",
    "coefs_array = []\n",
    "errors_array = []\n",
    "corr_matrixes = []\n",
    "for i in range(diffs.shape[0]):\n",
    "    y_approximated, coefs, pcov = approximated(\n",
    "        energies[1:13], res[i][1:13], error_sigma[i][1:13])\n",
    "    y_approximated_array.append(y_approximated)\n",
    "    coefs_array.append(coefs)\n",
    "    errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "    corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "y_approximated, coefs, pcov = approximated(\n",
    "    bdt_J19_5M_0.energy+1.022, 100*bdt_J19_5M_0.res, 100*bdt_J19_5M_0.res_err)\n",
    "y_approximated_array.append(y_approximated)\n",
    "coefs_array.append(coefs)\n",
    "errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "y_approximated, coefs, pcov = approximated(\n",
    "    bdt_J19_5M_23.energy+1.022, 100*bdt_J19_5M_23.res, 100*bdt_J19_5M_23.res_err)\n",
    "y_approximated_array.append(y_approximated)\n",
    "coefs_array.append(coefs)\n",
    "errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "corr_matrixes = np.array(corr_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [0, 3, 1, 4, 2, 5]\n",
    "coefs_df = pd.DataFrame(\n",
    "    np.hstack((coefs_array, errors_array))\n",
    ")[reindex]\n",
    "coefs_df.columns = ['a', r'$\\Delta a$', 'b', r'$\\Delta b$', 'c', r'$\\Delta c$']\n",
    "\n",
    "a = np.array(coefs_array).T[0]\n",
    "b = np.array(coefs_array).T[1]\n",
    "c = np.array(coefs_array).T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = np.linspace(0.8, 11.5, 1000)\n",
    "plot_results(appr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The JUNO collaboration., Abusleme, A., Adam, T. et al. Calibration strategy of the JUNO experiment. J. High Energ. Phys. 2021, 4 (2021). https://doi.org/10.1007/JHEP03(2021)004**\n",
    "\n",
    "It was found, numerically, that the JUNO baseline requirement to determine the MO to 3 â€“ 4 $\\sigma$ significance could be translated into a convenient requirement on an effective resolution $\\tilde{a}$ as:\n",
    "\n",
    "$$\\tilde{a} \\equiv \\sqrt{(a)^2 + (1.6 \\times b)^2 + \\left(\\frac{c}{1.6}\\right)^2} \\leq 3\\%$$\n",
    "\n",
    "Let's calculate the variance as follows:\n",
    "\n",
    "$$\\Delta \\tilde{a}^2 = \\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\Delta a \\right)^2 +\n",
    "                       \\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\Delta b \\right)^2 +\n",
    "                       \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\Delta c \\right)^2 +\n",
    "2 \\left[\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\right) r_{ab} \\Delta a \\Delta b +\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial a} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\right) r_{ac} \\Delta a \\Delta c +\n",
    "\\left(\\frac{\\partial \\tilde{a}}{\\partial b} \\right) \\left(\\frac{\\partial \\tilde{a}}{\\partial c} \\right) r_{bc} \\Delta b \\Delta c\n",
    "\\right]$$\n",
    "\n",
    "Then:\n",
    "\n",
    "$$\\Delta \\tilde{a}^2 = \\frac{\\left(a\\Delta a\\right)^2 + \\left(2.56\\times b\\Delta b\\right)^2 + \\left(\\frac{c\\Delta c}{2.56}\\right)^2}{\\tilde{a}^2} + 2 \\left[\n",
    "\\frac{2.56ab}{\\tilde{a}^2} r_{ab} \\Delta a \\Delta b +\n",
    "\\frac{ac}{2.56\\tilde{a}^2} r_{ac} \\Delta a \\Delta c +\n",
    "\\frac{bc}{\\tilde{a}^2} r_{bc} \\Delta b \\Delta c\n",
    "\\right] = \n",
    "\\frac{1}{\\tilde{a}^2} \\left[\n",
    "\\left(a\\Delta a\\right)^2 + \\left(2.56\\times b\\Delta b\\right)^2 + \\left(\\frac{c\\Delta c}{2.56}\\right)^2 +\n",
    "5.12 a b r_{ab} \\Delta a \\Delta b + \n",
    "\\frac{ac}{1.28} r_{ac} \\Delta a \\Delta c +\n",
    "2bcr_{bc} \\Delta b \\Delta c\n",
    "\\right]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = coefs_df.round(3)\n",
    "coefs_df.index = names\n",
    "coefs_df[r'$\\tilde{a}$'] = (coefs_df['a']**2 + (1.6 * coefs_df['b'])**2 + (coefs_df['c'] / 1.6)**2)**0.5 \n",
    "coefs_df[r'$\\Delta \\tilde{a}$'] = np.sqrt( (coefs_df['a']*coefs_df[r'$\\Delta a$'])**2 + \\\n",
    "                                           (2.56*coefs_df['b']*coefs_df[r'$\\Delta b$'])**2 + \\\n",
    "                                           (coefs_df['c']*coefs_df[r'$\\Delta c$'] / 2.56)**2) / coefs_df[r'$\\tilde{a}$']\n",
    "\n",
    "coefs_df[r'$\\Delta \\tilde{a}$'] = np.sqrt(\n",
    "    coefs_df[r'$\\Delta \\tilde{a}$']**2 + 2 * (\n",
    "        1.6**2 * coefs_df['a'] * coefs_df['b'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 0, 1] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta b$'] +\\\n",
    "        \n",
    "        coefs_df['a'] * coefs_df['c'] / (coefs_df[r'$\\tilde{a}$']**2 * 1.6**2) *\\\n",
    "        corr_matrixes[:, 0, 2] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta c$'] +\\\n",
    "\n",
    "        coefs_df['b'] * coefs_df['c'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 1, 2] * coefs_df[r'$\\Delta b$'] * coefs_df[r'$\\Delta c$']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run['output/coefs_df'].upload(File.as_html(coefs_df))\n",
    "log_table('output/coefs_df', coefs_df)\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune import log_metric\n",
    "log_metric('a_tilde', coefs_df[r'$\\tilde{a}$']['Elecsim 5M Real'])\n",
    "log_metric('a_tilde_std', coefs_df[r'$\\Delta \\tilde{a}$']['Elecsim 5M Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df.reset_index().to_csv('{}/results/params.csv'.format(run_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "neptune": {
   "notebookId": "398ccb38-2583-4296-887f-cfee13a48e82",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
